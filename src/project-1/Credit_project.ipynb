{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN-STK5000/9000 - Adaptive methods for data-based decision making\n",
    "## Credit Project\n",
    "\n",
    "The code to reproduce experiments can be found [here](https://github.com/gsel9/ml-society-science).\n",
    "\n",
    "#### Syed Moeen Ali Naqvi - Geir Severin Rakh Elvatun Langberg - Markus Sverdvik Heiervang  \n",
    "***\n",
    "\n",
    "### Part 1: Banker agent\n",
    "In this notebook, we display and comment on the development of our banker model, and measure it against the random banker, as well as documenting the implementations of the different methods used for the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Implementing expected utility\n",
    "\n",
    "Our action space $\\mathcal{A}$ is binary: $\\mathcal{A} = \\{0, 1\\} = \\{a_1, a_2\\} = \\{ \\text{refuse_loan}, \\text{grant_loan} \\}$\n",
    "\n",
    "\n",
    "To calculate the expected utility, we consider two actions: $a_1$ granting the loan or $a_2$ not granting a loan. Moreover, if granting a loan, the outcome at the end of the lending period $n$ is that it can be either fully repaid $\\omega_1$ or not repaid $\\omega_2$. The utility of granting a loan of $m$ credits that is also repaid is $m((1 + r)^n - 1)$, whereas, if the loan is not repaid, the utility is $-m$. In case of not granting the loan, the utility is zero. Thus, given the probability of being credit-worthy, $P(\\omega_1)$, the expected utility is  \n",
    "\n",
    "\n",
    "$$\n",
    "    \\mathbb{E}(U \\mid a) = m((1 + r)^n - 1)P(\\omega_1) - m(1 - P(\\omega_1)).\n",
    "$$\n",
    "\n",
    "This calculation is implemented as follows\n",
    "\n",
    "\n",
    "```Python\n",
    "def expected_utility(self, x: pd.Series, action: int) -> float:\n",
    "\n",
    "        if action:\n",
    "            # Probability of being credit worthy.\n",
    "            pi = self.predict_proba(x)\n",
    "\n",
    "            return x[\"amount\"] * ((1 + self.rate) ** x[\"duration\"] - 1) * pi - x[\"amount\"] * (1 - pi)\n",
    "\n",
    "        return 0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Implementing the fit function\n",
    "\n",
    "We are using Random forest classifier to fit a model for calculating the probability of credit-worthiness for a creditor. Random forests (RF) construct many individual decision trees at training. Predictions from all trees are pooled to make the final prediction; the mode of the classes for classification. As they use a collection of results to make a final decision, they are referred to as Ensemble techniques.\n",
    "\n",
    "We are using scikit-learn to implement the classifier. We have included optional hyper-parameter tuning before fitting the model.\n",
    "\n",
    "Following is the code for fit():\n",
    "\n",
    "```Python\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
    "        if self.optimize:\n",
    "            #Finding optimal paramters\n",
    "            param_grid = [{\n",
    "                'bootstrap' : [True],\n",
    "                'max_features' : list(range(10,20,1)),\n",
    "                'max_depth' : list(range(10,100,10)),\n",
    "                'n_estimators' : list(range(25,150,25))\n",
    "            }]\n",
    "\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator = RandomForestClassifier(), param_grid = param_grid, cv = 5\n",
    "            )\n",
    "            grid_search.fit(X, y)\n",
    "            self.classifier = RandomForestClassifier(\n",
    "                random_state=self.random_state, **grid_search.best_params_\n",
    "            )\n",
    "        else:\n",
    "            self.classifier = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                random_state=self.random_state,\n",
    "                class_weight=\"balanced\"\n",
    "            )\n",
    "            \n",
    "        self.classifier.fit(X,y)\n",
    "\n",
    "```\n",
    "\n",
    "The method predict_proba() ensures that the fit() is called beforehand and predicts the probability of the loan being returned. \n",
    "\n",
    "Following is the code for predict_proba():\n",
    "\n",
    "```Python\n",
    "    def predict_proba(self, x: pd.Series) -> float:\n",
    "        if not hasattr(self, \"classifier\"):\n",
    "            raise ValueError(\"This Group4Banker instance is not fitted yet. Call 'fit' \"\n",
    "                             \"with appropriate arguments before using this method.\")\n",
    "\n",
    "        x_reshaped = np.reshape(x.to_numpy(), (1,-1))\n",
    "\n",
    "        return self.classifier.predict_proba(x_reshaped)[0][0]\n",
    "```\n",
    "\n",
    "We are assuming that the labelling process is correct and the labels represent the ground truth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Get best action\n",
    "\n",
    "\n",
    "Assuming that we are maximising utility, a general function would be\n",
    "\n",
    "$$\n",
    "\\text{best_action}(x) = \\underset{a \\in \\mathcal{A}}{\\text{argmax}} \\  \\mathbb{E}(U \\mid a)\n",
    "$$\n",
    "\n",
    "but since our action space is binary, it can be expressed as\n",
    "\n",
    "$$  \n",
    "\\text{best_action}(x) = \\begin{cases}\n",
    "    1,& \\text{if } \\mathbb{E}(U \\mid a=1) > 0\\\\\n",
    "    0,              & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We can translate this into python code as such:\n",
    "\n",
    "```Python\n",
    "def get_best_action(self, x: pd.Series) -> int:\n",
    "        return int(self.expected_utility(x, 1) > 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Documenting the banker  \n",
    "\n",
    "For this part, we'll be interacting with the Group4Banker in the cells below. \n",
    "Before measuring the performance, we conduct a series of unit tests to assert that each method works for a few cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from group4_banker import Group4Banker\n",
    "import numpy as np\n",
    "\n",
    "# seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 2.159s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f5ec32db390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from test_group4_banker import TestGroup4Banker\n",
    "import unittest\n",
    "# We'll need these arguments when running the tests in jupyter notebook\n",
    "unittest.main(argv=[\"first-arg-is-ignored\"], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rewrote the TestLending script into a neat command-line interface so that we can customize the programs parameters.   \n",
    "This will also display progress of the training, since the classifier might take some time.  \n",
    "\n",
    "From this, we can observe that our banker performs better than the RandomBanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=0.05, n_tests=100, seed=12\n",
      "\n",
      "Testing on class: RandomBanker ...\n",
      "100%|█████████████████████████████████████████| 100/100 [00:06<00:00, 16.33it/s]\n",
      "Results:\n",
      "\tAverage utility: 62194332770.39753\n",
      "\tAverage return on investment: 1662784.8621222847\n",
      "\n",
      "Testing on class: Group4Banker ...\n",
      "100%|█████████████████████████████████████████| 100/100 [02:54<00:00,  1.66s/it]\n",
      "Results:\n",
      "\tAverage utility: 154030042326.10663\n",
      "\tAverage return on investment: 3563445.2297234936\n"
     ]
    }
   ],
   "source": [
    "!python3 TestLendingV2.py ../../data/credit/D_valid.csv --n-tests 100 --seed 12 --interest-rate 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our banker performs on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=0.05, n_tests=100, seed=11\n",
      "\n",
      "Testing on class: RandomBanker ...\n",
      "100%|█████████████████████████████████████████| 100/100 [00:06<00:00, 15.37it/s]\n",
      "Results:\n",
      "\tAverage utility: 286821119298.73846\n",
      "\tAverage return on investment: 4944685.923886744\n",
      "\n",
      "Testing on class: Group4Banker ...\n",
      "100%|█████████████████████████████████████████| 100/100 [02:53<00:00,  1.71s/it]\n",
      "Results:\n",
      "\tAverage utility: 490355107143.02966\n",
      "\tAverage return on investment: 11223170.155701187\n"
     ]
    }
   ],
   "source": [
    "!python3 TestLendingV2.py ../../data/credit/D_train.csv --n-tests 100 --seed 11 --interest-rate 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Critical evaluation of banker agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Is it possible to ensure that your policy maximises revenue? How can you take into account\n",
    "the uncertainty due to the limited and/or biased data? What if you have to decide for credit\n",
    "for thousands of individuals and your model is wrong? How should you take that type of\n",
    "risk into account?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Severin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Does the existence of this database raise any privacy concerns? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database contains information about individuals such as sex, age, personal status, employment status, property, housing status which can be used to identify individuals when linked with other publicly available databases (e.g., social media, tax data, health records, voter's data, etc). If the data is available publicly, a linkage attack can be used to identify many individuals in this database. \n",
    "\n",
    "### If the database was secret (and only known by the bank), but the credit decisions were public, how would that affect privacy?\n",
    "\n",
    "This will definitely increase the overall privacy of the data. However, an attacker can still infer information based on the published credit decisions depending on how the decisions are published. For example, if credit decision include data about the amount and duration of loan, and an attacker already knows certain attributes of an individual, it is possible to identify an individual.\n",
    "\n",
    "### (a) Explain how you would protect the data of the people in the training set.\n",
    "\n",
    "The training set data can be protected by adopting the randomized response mechanism (i.e. Global privacy model). For that, we return the true credit decision with probability $\\leq 1$. The calculation of each response would not be dependent on the query. \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "### (b) Explain how would protect the data of the people that apply for new loans.\n",
    "\n",
    "Whether someone who doesn't already exist in our database, or someone who has some history with the considered credit system, the information provided is sensitive and it needs to be randomized. \n",
    "\n",
    "For that, we can transform each attribute independently by adding a noise to it (i.e. local privacy model). This can be represented as:\n",
    "\n",
    "$\\pi(a|x) = \\underset{i}{\\Huge \\Pi} \\pi(a_i|x_i)$\n",
    "   \n",
    "where $x$ represents the complete data and $a = (a_1,.....,a_n)$ represents the mechanism's output. \n",
    "\n",
    "The method is $\\epsilon-$differentially private.\n",
    "\n",
    "### (c) Implement a private decision making mechanism for (b)\n",
    "\n",
    "\n",
    "### Estimate the amount of loss in utility as you change the privacy guarantee.\n",
    "\n",
    "The exponential mechanism defines the utility of a query $q$ for a user $x$ with a response $a$ as:\n",
    "\n",
    "$\\pi(a|x) = \\frac{e^{\\epsilon U(q,a,x) / \\Delta U}}{\\sum_{a'}e^{\\epsilon U(q,a',x) / \\Delta U}}$\n",
    "\n",
    "where $\\Delta U = sup_{xNx'}|U(q,a,x) - U(q,a,x)|$\n",
    "\n",
    "where the lower the value of $\\epsilon$, the more randomized a result would be.\n",
    "\n",
    "For calculating the loss in utility according to privacy, we can come up with the formula: \n",
    "\n",
    "$\\Delta U = Utility_{x, repaid} - Utility_{x, defaulted} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Consider the fairness of this banker model. What interesting features does it consider?   \n",
    "\n",
    "Looking at the dataset, typical necessary features would be credit history, \n",
    "amount and lending period. \n",
    "However, some of the features seem to look at details about the person\n",
    "that might just be loosely connected to return of loan. \n",
    "The features Age, phone, foreign and sex/status are all taken into account when the model evaluates, which means that it can generate biases on these grounds.\n",
    "So we have to talk about which biases are fair, and which we might want to avoid.\n",
    "\n",
    "The sex/feature attribute is defined as such\n",
    "     \n",
    "```console\n",
    "Attribute 9:  (qualitative)\n",
    "\t      Personal status and sex\n",
    "\t      A91 : male   : divorced/separated\n",
    "\t      A94 : male   : married/widowed\n",
    "\t      A92 : female : divorced/separated/married\n",
    "          A93 : male   : single\n",
    "\t      A95 : female : single    \n",
    "```\n",
    "(from the dataset description in data/credit/german.doc)\n",
    "\n",
    "What is interresting to see here is that there are more categories for male than female.\n",
    "Male+divorced/separaeted is a different category than male+married/widowed, but when it comes to female, these categories are merged into one. Why is that? Could it be because we're compensating for missing data? Or are we making assumptions about how this affects the likelihood of returning loan?\n",
    "    \n",
    "    \n",
    "* Consider the model with repsect to Group fairness and conditional independece:\n",
    "    Does is evaluate on fair grounds?  Can this model be subject to discrimination?  \n",
    "    \n",
    "Because we are talking about loan and maximizing revenue, this model has to discriminate on some grounds, such as social class (e.g. job/salary). \n",
    "The ability to take a loan is something that directly affects your opportunities in the society, so if equal opportunity for, say gender, is something we strive for, it is important to ensure that that there is no bias with respect to gender alone in the model. Since this attribute is part of the data we're training on, the model is guaranteed to have some, though possibly microscopical, bias with respect to sex. If we want to remove this bias, we should drop information about sex from the dataset, and instead, only use the categorical features married, divorced, widowed, single.  \n",
    "\n",
    "\n",
    "* What can you say about the fairness with respect to Individual Independence and Meritocracy \n",
    "\n",
    "We have to discuss which terms should make someone \"qualify\" for loan. Other that that, if we only consider relevant attributes, the model should in turn make a meritocratic evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether the biases can have any effect on the decision making, we can test it by comparing estimated probabilities of single women compared to single men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of returns for single males in the train set:\n",
      " 0.6980392156862745\n",
      "Proportion of returns for single females in the train set:\n",
      " 0.6730769230769231 \n",
      "\n",
      "Estimated probability for single male: 0.54 \n",
      "Estimated probabiltiy for single female: 0.56 \n",
      "Absolute difference 0.020000000000000018 \n",
      "\n",
      "Estimated probability for single male: 0.59 \n",
      "Estimated probabiltiy for single female: 0.61 \n",
      "Absolute difference 0.020000000000000018 \n",
      "\n",
      "Estimated probability for single male: 0.82 \n",
      "Estimated probabiltiy for single female: 0.83 \n",
      "Absolute difference 0.010000000000000009 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 test_biases.py --seed 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in probability estimates is microscopical, but still exsistent.  \n",
    "We can create an edge-case where the decisions would be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best action for single male: 0\n",
      "Best action for single female: 1\n"
     ]
    }
   ],
   "source": [
    "from test_biases import get_trained_model, get_encoded_features\n",
    "import pandas as pd\n",
    "decision_maker = get_trained_model(0.05)\n",
    "categories = get_encoded_features()\n",
    "\n",
    "values = [26.5, 25938, 7, 2, 38, 0, 6, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, \n",
    "          0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "\n",
    "x_male = pd.Series(dict(zip(categories, values)))\n",
    "x_female = x_male.copy()\n",
    "x_male[\"marital status_3\"], x_female[\"marital status_5\"] = 1, 1\n",
    "\n",
    "print(\"Best action for single male:\", decision_maker.get_best_action(x_male[categories]))\n",
    "print(\"Best action for single female:\", decision_maker.get_best_action(x_female[categories]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, though all the other features are identical, our banker will give loan to the single female, but not the single male. So our model can be subject to discrimination, though unlikely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
