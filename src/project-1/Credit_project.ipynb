{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN-STK5000/9000 - Adaptive methods for data-based decision making\n",
    "## Credit Project\n",
    "\n",
    "The code to reproduce experiments can be found [here](https://github.com/gsel9/ml-society-science).\n",
    "\n",
    "#### Syed Moeen Ali Naqvi - Geir Severin Rakh Elvatun Langberg - Markus Sverdvik Heiervang  \n",
    "***\n",
    "\n",
    "### Part 1: Banker agent\n",
    "In this notebook, we display and comment on the development of our banker model, and measure it against the random banker, as well as documenting the implementations of the different methods used for the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Implementing expected utility\n",
    "\n",
    "Our action space $\\mathcal{A}$ is binary: $\\mathcal{A} = \\{0, 1\\} = \\{a_1, a_2\\} = \\{ \\text{refuse_loan}, \\text{grant_loan} \\}$\n",
    "\n",
    "\n",
    "To calculate the expected utility, we consider two actions: $a_1$ granting the loan or $a_2$ not granting a loan. Moreover, if granting a loan, the outcome at the end of the lending period $n$ is that it can be either fully repaid $\\omega_1$ or not repaid $\\omega_2$. The utility of granting a loan of $m$ credits that is also repaid is $m((1 + r)^n - 1)$, whereas, if the loan is not repaid, the utility is $-m$. In case of not granting the loan, the utility is zero. Thus, given the probability of being credit-worthy, $P(\\omega_1)$, the expected utility is  \n",
    "\n",
    "\n",
    "$$\n",
    "    \\mathbb{E}(U \\mid a) = m((1 + r)^n - 1)P(\\omega_1) - m(1 - P(\\omega_1)).\n",
    "$$\n",
    "\n",
    "This calculation is implemented as follows\n",
    "\n",
    "\n",
    "```Python\n",
    "def expected_utility(self, x: pd.Series, action: int) -> float:\n",
    "\n",
    "        if action:\n",
    "            # Probability of being credit worthy.\n",
    "            pi = self.predict_proba(x)\n",
    "\n",
    "            return x[\"amount\"] * ((1 + self.rate) ** x[\"duration\"] - 1) * pi - x[\"amount\"] * (1 - pi)\n",
    "\n",
    "        return 0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Implementing the fit function\n",
    "\n",
    "We are using Random forest classifier to fit a model for calculating the probability of credit-worthiness for a creditor. Random forests (RF) construct many individual decision trees at training. Predictions from all trees are pooled to make the final prediction; the mode of the classes for classification. As they use a collection of results to make a final decision, they are referred to as Ensemble techniques.\n",
    "\n",
    "We are using scikit-learn to implement the classifier. We have included optional hyper-parameter tuning before fitting the model.\n",
    "\n",
    "Following is the code for fit():\n",
    "\n",
    "```Python\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
    "        if self.optimize:\n",
    "            #Finding optimal paramters\n",
    "            param_grid = [{\n",
    "                'bootstrap' : [True],\n",
    "                'max_features' : list(range(10,20,1)),\n",
    "                'max_depth' : list(range(10,100,10)),\n",
    "                'n_estimators' : list(range(25,150,25))\n",
    "            }]\n",
    "\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator = RandomForestClassifier(), param_grid = param_grid, cv = 5\n",
    "            )\n",
    "            grid_search.fit(X, y)\n",
    "            self.classifier = RandomForestClassifier(\n",
    "                random_state=self.random_state, **grid_search.best_params_\n",
    "            )\n",
    "        else:\n",
    "            self.classifier = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                random_state=self.random_state,\n",
    "                class_weight=\"balanced\"\n",
    "            )\n",
    "            \n",
    "        self.classifier.fit(X,y)\n",
    "\n",
    "```\n",
    "\n",
    "The method predict_proba() ensures that the fit() is called beforehand and predicts the probability of the loan being returned. \n",
    "\n",
    "Following is the code for predict_proba():\n",
    "\n",
    "```Python\n",
    "    def predict_proba(self, x: pd.Series) -> float:\n",
    "        if not hasattr(self, \"classifier\"):\n",
    "            raise ValueError(\"This Group4Banker instance is not fitted yet. Call 'fit' \"\n",
    "                             \"with appropriate arguments before using this method.\")\n",
    "\n",
    "        x_reshaped = np.reshape(x.to_numpy(), (1,-1))\n",
    "\n",
    "        return self.classifier.predict_proba(x_reshaped)[0][0]\n",
    "```\n",
    "\n",
    "We are assuming that the labelling process is correct and the labels represent the ground truth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Get best action\n",
    "\n",
    "\n",
    "Assuming that we are maximising utility, a general function would be\n",
    "\n",
    "$$\n",
    "\\text{best_action}(x) = \\underset{a \\in \\mathcal{A}}{\\text{argmax}} \\  \\mathbb{E}(U \\mid a)\n",
    "$$\n",
    "\n",
    "but since our action space is binary, it can be expressed as\n",
    "\n",
    "$$  \n",
    "\\text{best_action}(x) = \\begin{cases}\n",
    "    1,& \\text{if } \\mathbb{E}(U \\mid a=1) > 0\\\\\n",
    "    0,              & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We can translate this into python code as such:\n",
    "\n",
    "```Python\n",
    "def get_best_action(self, x: pd.Series) -> int:\n",
    "        return int(self.expected_utility(x, 1) > 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Documenting the banker  \n",
    "\n",
    "For this part, we'll be interacting with the Group4Banker in the cells below. \n",
    "Before measuring the performance, we conduct a series of unit tests to assert that each method works for a few cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from group4_banker import Group4Banker\n",
    "import numpy as np\n",
    "\n",
    "# seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 2.956s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f8fa948e110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from test_group4_banker import TestGroup4Banker\n",
    "import unittest\n",
    "# We'll need these arguments when running the tests in jupyter notebook\n",
    "unittest.main(argv=[\"first-arg-is-ignored\"], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rewrote the TestLending script into a neat command-line interface so that we can customize the programs parameters.   \n",
    "This will also display progress of the training, since the classifier might take some time.  \n",
    "\n",
    "From this, we can observe that our banker performs better than the RandomBanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=0.05, n_tests=100, seed=12\n",
      "\n",
      "Testing on class: RandomBanker ...\n",
      "100%|█████████████████████████████████████████| 100/100 [00:08<00:00, 12.08it/s]\n",
      "Results:\n",
      "\tAverage utility: 62194332770.39753\n",
      "\tAverage return on investment: 1662784.8621222847\n",
      "\n",
      "Testing on class: Group4Banker ...\n",
      "100%|█████████████████████████████████████████| 100/100 [03:12<00:00,  1.85s/it]\n",
      "Results:\n",
      "\tAverage utility: 154030042326.10663\n",
      "\tAverage return on investment: 3563445.2297234936\n"
     ]
    }
   ],
   "source": [
    "!python3 TestLendingV2.py ../../data/credit/D_valid.csv --n-tests 100 --seed 12 --interest-rate 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our banker performs on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=0.05, n_tests=100, seed=11\n",
      "\n",
      "Testing on class: RandomBanker ...\n",
      "100%|█████████████████████████████████████████| 100/100 [00:06<00:00, 15.39it/s]\n",
      "Results:\n",
      "\tAverage utility: 286821119298.73846\n",
      "\tAverage return on investment: 4944685.923886744\n",
      "\n",
      "Testing on class: Group4Banker ...\n",
      "100%|█████████████████████████████████████████| 100/100 [03:04<00:00,  1.76s/it]\n",
      "Results:\n",
      "\tAverage utility: 490355107143.02966\n",
      "\tAverage return on investment: 11223170.155701187\n"
     ]
    }
   ],
   "source": [
    "!python3 TestLendingV2.py ../../data/credit/D_train.csv --n-tests 100 --seed 11 --interest-rate 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Critical evaluation of banker agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Is it possible to ensure that your policy maximises revenue? How can you take into account\n",
    "the uncertainty due to the limited and/or biased data? What if you have to decide for credit\n",
    "for thousands of individuals and your model is wrong? How should you take that type of\n",
    "risk into account?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we cannot ensure that the policy maximises revenue because the probability estimates $P(\\omega_1)$ and $P(\\omega_2)$ about the outcome of events $\\omega_1$ and $\\omega_2$ might be biased. However, from a theoretical point of view where we assume $P(\\omega_1)$ and $P(\\omega_2)$ are true, to maximize revenue we desire \n",
    "\n",
    "$$\n",
    "    \\mathbb{E}(U \\mid a) > 0 \\Rightarrow m((1 + r)^n - 1)P(\\omega_1) > mP(\\omega_2) \\Leftrightarrow (1 + r)^n - 1 > \\frac{P(\\omega_2)}{P(\\omega_1)}, \\quad P(\\omega_1) > 0\n",
    "$$\n",
    "\n",
    "To select parameters $n$ and $r$ ensuring $\\mathbb{E}(U \\mid a) > 0$ we can either consider \n",
    "\n",
    "$$\n",
    "    n > \\frac{\\ln P(\\omega_2) - \\ln P(\\omega_1)}{\\ln (1 + r)}, \\quad r, P(\\omega_1), P(\\omega_2) > 0\n",
    "$$\n",
    "\n",
    "for fixed $r$, or \n",
    "\n",
    "$$\n",
    "r > \\exp\\left ( \\frac{\\ln P(\\omega_2) - \\ln P(\\omega_1)}{n} \\right ) - 1, \\quad n, P(\\omega_1), P(\\omega_2) > 0\n",
    "$$\n",
    "\n",
    "for fixed $n$.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "To obtain a model performance measure that is more robust than a single point estimate, one can consider a re-sampling technique - such as cross-validation of bootstraping - to derive an empirical distribution of performance. In our approach, we use bootstraping to predict the optial actions on several random subsets of the test data. This produces a matrix $\\mathbf{\\hat{Y}} \\in \\left \\{ a_0, a_1 \\right \\}^{N \\times M}$ of predicted actions on $N$ bootstrap samples of size $P$. Note that the predicted actions corresponds to the ground truths $\\mathbf{Y}$ in the test data.\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "We use a Bayesian approach to evaluate the effect of an increasing number of samples on the model by comparing the posterior probability of rejecting $a_0$ (grant loan) when $a_1$ (don't grant loan) is true, to a ground truth derived from the test data. That is, we evaluate the model's ability to reject a loan that is unlikely to be repaid. The reference rejection rate $\\hat{\\mu}$ of $H_0$ is computed from the test data bootstrap samples\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_0 = \\frac{1}{NM} \\sum_{n, m} \\mathbb{I}(Y_{n, m} = 0)\n",
    "$$\n",
    "\n",
    "Moreover, assuming $Y_{n, m}$ are i.i.d., we include a $1 - \\delta$ confidence interval around $\\hat{\\mu}_0$ by using Hoeffding's inequality \n",
    "$$\n",
    "    \\left | \\hat{\\mu}_0 - \\mathbb{E}\\left \\{ \\hat{\\mu}_0 \\right \\} \\right | \\leq \\sqrt{\\frac{\\ln2 \\delta}{2n}} \\Rightarrow \\mathbb{E}\\left \\{ \\hat{\\mu}_0 \\right \\} \\in \\left [ \\hat{\\mu}_0 - \\sqrt{\\frac{\\ln2 \\delta}{2n}}, \\hat{\\mu}_0 + \\sqrt{\\frac{\\ln2 \\delta}{2n}} \\right ],\n",
    "$$\n",
    "bounding the expected value of $\\hat{\\mu}_0$. \n",
    "\n",
    "In experiments, we ran 200 iterations of 50 bootstrap samples for $\\delta = 0.05$. The code to reproduce our experiments can be found in `action_sensitivity.py`. \n",
    "\n",
    "In the following figure, we compare the probability of rejecting $H_0$ given model esimtates to the reference rate $\\hat{\\mu}_0$ derived from test data. The figure shows that the probability of granting a loan that will not be repaid converges to $\\hat{\\mu}_0$ as the number of boostrap samples increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"550\"\n",
       "            src=\"reject_null_hypo.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8fa8610990>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\"reject_null_hypo.pdf\", width=800, height=550)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further enhance model performance, we can update our prediction model providing probability estimates by including more *Decision Trees* in the *Random Forest*. The additional trees are then trained on the test data after predictions are performed. This mechanism could be implemented as follows:\n",
    "\n",
    "```Python\n",
    "def adaptive_predict_proba(X, batch_size=0, n_extra_estimators=0):\n",
    "    \"\"\"Use test data to re-train the model after each decision.\"\"\"\n",
    "    \n",
    "    y_pred = model.predict()\n",
    "    \n",
    "    # Add more decision trees to the model and train these using the new training data.\n",
    "    model.set_params(n_estimators=int(model.n_estimators) + int(n_extra_estimators), \n",
    "                     warm_start=True)\n",
    "    model.train(X)\n",
    "        \n",
    "    return y_pred\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Does the existence of this database raise any privacy concerns? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database contains information about individuals such as sex, age, personal status, employment status, property, housing status which can be used to identify individuals when linked with other publicly available databases (e.g., social media, tax data, health records, voter's data, etc). If the data is available publicly, a linkage attack can be used to identify many individuals in this database. \n",
    "\n",
    "If the database was secret (and known only by the bank), but the credit decisions were public, the overall privacy of the data will definitely increase. However, an attacker can still infer information based on the published credit decisions depending on how the decisions are published. For example, if credit decision include data about the amount and duration of loan, and an attacker already knows certain attributes of an individual, it is possible to identify an individual.\n",
    "\n",
    "\n",
    "The training set data of people in the database can be protected by adopting the randomized response mechanism (i.e. Global privacy model). For that, we return the true credit decision with probability $\\leq 1$. The calculation of each response would not be dependent on the query. \n",
    "\n",
    "Whether someone who doesn't already exist in our database, or someone who has some history with the considered credit system, the information provided is sensitive and it needs to be randomized. For that, we can transform each attribute independently by adding a noise to it (i.e. local privacy model). This can be represented as:\n",
    "\n",
    "$$\n",
    "\\pi(a|x) = \\underset{i}{\\Huge \\Pi} \\pi(a_i|x_i)\n",
    "$$\n",
    "   \n",
    "where $x$ represents the complete data and $a = (a_1,.....,a_n)$ represents the mechanism's output. The method is $\\epsilon-$differentially private.\n",
    "\n",
    "We are using localized privacy model for our private decision making mechanism. We have used Laplace transformation for the numerical features in our data. It is defined as: \n",
    "\n",
    "$$\n",
    "\\pi(a|x) = Laplace(f(x), \\lambda)\n",
    "$$ \n",
    "\n",
    "for any function $f: \\chi \\to \\mathbb{R}$ where Laplace density is defined as: \n",
    "\n",
    "$$\n",
    "\\rho(\\omega | \\mu, \\lambda) = \\frac{1}{2\\lambda}exp(-\\frac{|\\omega - \\mu|}{\\lambda})$$\n",
    "with mean $\\mu$ and variance $2\\lambda^2$.\n",
    "\n",
    "For the categorical features, we have used the randomized response for a certain probability.\n",
    "\n",
    "Our implementation for the randomize_data() is as follows:\n",
    "\n",
    "\n",
    "```Python\n",
    "\n",
    "def randomize_data(df, numerical_features, categorical_features, probability, laplace_delta):\n",
    "    df_copy = df.df.copy()\n",
    "\n",
    "    for column_name in categorical_features:\n",
    "        temp_col = df_copy[column_name]\n",
    "        random_index = np.random.choice(\n",
    "            a=[True,False],\n",
    "            size = temp_col.size, \n",
    "            p=[probability, 1-probability]\n",
    "        )\n",
    "        new_datapoints = np.random.choice(\n",
    "            np.unique(temp_col),\n",
    "            size = random_index.sum()\n",
    "        )\n",
    "        temp_col[random_index] = new_datapoints\n",
    "        df_copy[column_name] = temp_col\n",
    "\n",
    "    for column_name in numerical_features:\n",
    "        temp_col = df_copy[column_name]\n",
    "        noise = np.random.laplace(0, laplace_delta, size = temp_col.size)\n",
    "        noise *= temp_col.std()\n",
    "        df_copy[column_name] = temp_col + noise \n",
    "    return df_copy\n",
    "```\n",
    "\n",
    "The exponential mechanism defines the utility of a query $q$ for a user $x$ with a response $a$ as:\n",
    "\n",
    "$$\n",
    "\\pi(a|x) = \\frac{e^{\\epsilon U(q,a,x) / \\Delta U}}{\\sum_{a'}e^{\\epsilon U(q,a',x) / \\Delta U}}\n",
    "$$\n",
    "\n",
    "where $\\Delta U = sup_{xNx'}|U(q,a,x) - U(q,a,x)|$\n",
    "\n",
    "where the lower the value of $\\epsilon$, the more randomized a result would be.\n",
    "\n",
    "For calculating the loss in utility according to privacy, we can come up with the formula: \n",
    "\n",
    "$$\n",
    "\\Delta U = Utility_{x, original} - Utility_{x, private}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Is our banker model fair?\n",
    "* What interesting features does it consider?   \n",
    "\n",
    "Looking at the dataset, typical necessary features would be credit history, \n",
    "amount and lending period. \n",
    "However, some of the features seem to look at details about the person\n",
    "that might just be loosely connected to return of loan. \n",
    "The features Age, phone, foreign and sex/status are all taken into account when the model evaluates, which means that it can generate biases on these grounds.\n",
    "So we have to talk about which biases are fair, and which we might want to avoid.\n",
    "\n",
    "The sex/feature attribute is defined as such\n",
    "     \n",
    "```console\n",
    "Attribute 9:  (qualitative)\n",
    "\t      Personal status and sex\n",
    "\t      A91 : male   : divorced/separated\n",
    "\t      A94 : male   : married/widowed\n",
    "\t      A92 : female : divorced/separated/married\n",
    "          A93 : male   : single\n",
    "\t      A95 : female : single    \n",
    "```\n",
    "(from the dataset description in data/credit/german.doc)\n",
    "\n",
    "What is interresting to see here is that there are more categories for male than female.\n",
    "Male+divorced/separaeted is a different category than male+married/widowed, but when it comes to female, these categories are merged into one. Why is that? Could it be because we're compensating for missing data? Or are we making assumptions about how this affects the likelihood of returning loan?\n",
    "    \n",
    "    \n",
    "* Consider the model with repsect to Group fairness and conditional independece:\n",
    "    Does is evaluate on fair grounds?  Can this model be subject to discrimination?  \n",
    "    \n",
    "Because we are talking about loan and maximizing revenue, this model has to discriminate on some grounds, such as social class (e.g. job/salary). \n",
    "The ability to take a loan is something that directly affects your opportunities in the society, so if equal opportunity for, say gender, is something we strive for, it is important to ensure that that there is no bias with respect to gender alone in the model. Since this attribute is part of the data we're training on, the model is guaranteed to have some, though possibly microscopical, bias with respect to sex. If we want to remove this bias, we should drop information about sex from the dataset, and instead, only use the categorical features married, divorced, widowed, single.  \n",
    "\n",
    "\n",
    "* What can you say about the fairness with respect to Individual Independence and Meritocracy \n",
    "\n",
    "We have to discuss which terms should make someone \"qualify\" for loan. Other that that, if we only consider relevant attributes, the model should in turn make a meritocratic evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether the biases can have any effect on the decision making, we can test it by comparing estimated probabilities of single women compared to single men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of returns for single males in the train set:\n",
      " 0.6980392156862745\n",
      "Proportion of returns for single females in the train set:\n",
      " 0.6730769230769231 \n",
      "\n",
      "Estimated probability for single male: 0.54 \n",
      "Estimated probabiltiy for single female: 0.56 \n",
      "Absolute difference 0.020000000000000018 \n",
      "\n",
      "Estimated probability for single male: 0.59 \n",
      "Estimated probabiltiy for single female: 0.61 \n",
      "Absolute difference 0.020000000000000018 \n",
      "\n",
      "Estimated probability for single male: 0.82 \n",
      "Estimated probabiltiy for single female: 0.83 \n",
      "Absolute difference 0.010000000000000009 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 test_biases.py --seed 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in probability estimates is microscopical, but still exsistent.  \n",
    "We can create an edge-case where the decisions would be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best action for single male: 0\n",
      "Best action for single female: 1\n"
     ]
    }
   ],
   "source": [
    "from test_biases import get_trained_model, get_encoded_features\n",
    "import pandas as pd\n",
    "decision_maker = get_trained_model(0.05)\n",
    "categories = get_encoded_features()\n",
    "\n",
    "values = [26.5, 25938, 7, 2, 38, 0, 6, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, \n",
    "          0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "\n",
    "x_male = pd.Series(dict(zip(categories, values)))\n",
    "x_female = x_male.copy()\n",
    "x_male[\"marital status_3\"], x_female[\"marital status_5\"] = 1, 1\n",
    "\n",
    "print(\"Best action for single male:\", decision_maker.get_best_action(x_male[categories]))\n",
    "print(\"Best action for single female:\", decision_maker.get_best_action(x_female[categories]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, though all the other features are identical, our banker will give loan to the single female, but not the single male. So our model can be subject to discrimination, though unlikely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
